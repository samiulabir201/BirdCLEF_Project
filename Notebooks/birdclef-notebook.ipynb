{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **BirdCLEF 2024: Bird Sound Classification Project**","metadata":{}},{"cell_type":"markdown","source":"## Overview\n\nThis project focuses on classifying bird species from audio recordings using deep learning techniques. Leveraging advanced data augmentation, focal loss, and ensemble models, the goal is to achieve high performance in the BirdCLEF 2024 competition. The project encompasses data preprocessing, model training, evaluation, and inference, with support for exporting models in the ONNX format for optimized deployment.","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents:\n\n1. Environment Setup\n2. Configuration\n3. Data Preprocessing\n4. Dataset Handling\n5. Model Architecture\n6. Training Utilities\n7. Training Loop\n8. Evaluation\n9. Inference\n10. Visualization\n11. ONNX Export","metadata":{}},{"cell_type":"markdown","source":"## Environment Setup\n\nThe project begins by setting up the necessary environment, importing essential libraries and packages required for data manipulation, model building, training, and evaluation.","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport glob\nimport time\nimport shutil\nimport random\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport wandb\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\n\nfrom tqdm.notebook import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom torch.cuda import amp\nimport torch\nprint(f\"pytorch version is {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.cuda import amp\n\nimport torchvision\nfrom torchvision.transforms import v2 as transforms\n\nimport librosa\nimport torchaudio\nimport torchaudio.transforms as audioT\n\nif KAGGLE == False:\n    import nnAudio\n    from nnAudio import features\n    import albumentations\n    from audiomentations import Compose, SpecCompose, OneOf, AddGaussianNoise, AddColorNoise\n    from audiomentations import TimeStretch, PitchShift, Shift, SpecFrequencyMask, TimeMask\n    from audiomentations import Gain, GainTransition\n    from torcheval.metrics.functional import multiclass_auroc, multiclass_f1_score, multiclass_precision, multiclass_recall, multilabel_accuracy\nif KAGGLE == False:\n    from adan_pytorch import Adan\nimport timm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Key Components:**\n\n* **Data Manipulation:** numpy, pandas\n* **Machine Learning Utilities:** scikit-learn, torch, torchvision\n* **Data Augmentation:** albumentations, audiomentations\n* **Visualization:** matplotlib, seaborn\n* **Model Management:** timm, onnx, onnxruntime\n* **Experiment Tracking:** wandb (Weights & Biases)","metadata":{}},{"cell_type":"markdown","source":"## Configuration\n\nA configuration class centralizes all the settings and hyperparameters used throughout the project. This ensures easy management and modification of parameters.","metadata":{}},{"cell_type":"code","source":"class config:\n    if KAGGLE:\n        dir = \"/kaggle/input/birdclef-2024/\"\n    else:\n        dir = \"/mnt/d/kaggle/birdclef-2024/\"\n\n    wave_path = \"original_waves/second_30/\"\n    model_name = 'tf_efficientnet_b0'\n    pool_type = 'avg'\n\n    train_duration = 30  # Seconds of audio used for training\n    slice_duration = 5   # Duration of each slice fed into the model\n\n    test_duration = 5\n    train_drop_duration = 1\n\n    # Spectrogram parameters\n    sr = 32000\n    fmin = 20\n    fmax = 15000\n    n_mels = 128\n    n_fft = n_mels * 8\n    size_x = 512\n    hop_length = int(sr * slice_duration / size_x)\n    test_hop_length = int(sr * test_duration / size_x)\n    bins_per_octave = 12\n\n    # Cross-validation\n    nfolds = 5\n    inference_folds = [4]\n\n    # Training settings\n    enable_amp = True\n    train_batchsize = 32\n    valid_batchsize = 1\n    loss_type = \"BCEFocalLoss\"\n    lr = 1.0e-03\n    optimizer = 'adan'\n    weight_decay = 1.0e-02\n    es_patience = 5\n    deterministic = True\n    max_epoch = 9\n    aug_epoch = 6\n\n    # Data augmentation settings\n    useSecondary = True\n    secondary_label_value = 0.5\n    oversample = False\n    oversample_threthold = 60\n    seed = 42\n    wandb = True\n\n    # Augmentation flags\n    aug_noise = 0.0\n    aug_gain = 0.0\n    aug_wave_pitchshift = 0.0\n    aug_wave_shift = 0.0\n    aug_spec_xymasking = 0.0\n    aug_spec_coarsedrop = 0.0\n    aug_spec_hflip = 0.0\n    aug_spec_mixup = 0.0\n    aug_spec_mixup_prob = 0.5\n    alpha = 0.95\n\n    # Label smoothing\n    smoothing_value = 0.0\n\ncfg = config()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Highlights:**\n* **Data Paths:** Differentiates between Kaggle and local environments.\n* **Model Parameters:** Defines the model architecture and pooling strategy.\n* **Training Hyperparameters:** Learning rate, batch sizes, epochs, optimizer choice, etc.\n* **Data Augmentation:** Configurable flags for various augmentation techniques.\n* **Cross-Validation:** Specifies the number of folds and which folds to use during inference.\n","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### **Loading and Cleaning the Data**\n\nThe dataset is loaded from CSV files, and duplicate entries are removed to ensure data quality.","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(cfg.dir + \"sample_submission.csv\")\nLABELS = list(sample_submission.set_index(\"row_id\").columns)\n\nif KAGGLE == False:\n    train_csv = pd.read_csv(cfg.dir + \"train_eda.csv\")\n    train_csv[\"fileID\"] = train_csv[\"filename\"].map(lambda x: x.split(\"/\")[1][:-4])\nelse:\n    train_csv = pd.read_csv(cfg.dir + \"train_metadata.csv\")\n\nimport ast\ntrain_csv['new_target'] = train_csv['primary_label'] + ' ' + train_csv['secondary_labels'].map(lambda x: ' '.join(ast.literal_eval(x)))\ntrain_csv['len_new_target'] = train_csv['new_target'].map(lambda x: len(x.split()))\n\ntrain_csv[\"filename_tmp\"] = train_csv[\"filename\"].map(lambda x: x.split(\"/\")[1][:-4])\nduplicated_filenames = train_csv[\"filename_tmp\"].value_counts()[train_csv[\"filename_tmp\"].value_counts() > 1].index\ntrain_csv = train_csv[~train_csv[\"filename_tmp\"].isin(duplicated_filenames)]\ntrain_csv = train_csv.reset_index(drop=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Steps:**\n1. **Loading Sample Submission:** Retrieves the list of labels used in the competition.\n1. **Loading Training Data:**\n    For local environments, it reads train_eda.csv.\n    For Kaggle, it reads train_metadata.csv.\n1. **Creating New Targets:** Combines primary and secondary labels into a single target string.\n1. **Removing Duplicates:** Identifies and removes duplicate file entries to prevent overfitting.","metadata":{}},{"cell_type":"markdown","source":"## Dataset Handling\nA custom BirdCLEF_Dataset class inherits from torch.utils.data.Dataset to handle data loading, preprocessing, and augmentation.","metadata":{}},{"cell_type":"code","source":"class BirdCLEF_Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, augmentation=False, mode='train'):\n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.augmentation = augmentation\n\n    def __len__(self):\n        return len(self.df)\n\n    def normalize(self, x):\n        valid_values = x[x != float('-inf')]\n        mean_value = np.mean(valid_values)\n        x[x == float('-inf')] = mean_value\n        x = x - x.min()\n        x = x / x.max()\n        return x\n\n    def wave_tile_and_cutoff(self, data):\n        drop_duration = cfg.sr * cfg.train_drop_duration\n        use_duration = cfg.sr * cfg.train_duration\n\n        if len(data[0]) > drop_duration:\n            data = data[:, drop_duration:]\n\n        if len(data[0]) < use_duration:\n            iter = 1 + (use_duration) // len(data[0])\n            data = np.tile(data, (1, iter))\n\n        data = data[:, :use_duration]\n        return data\n\n    def label_smoothing(self, idx, target):\n        secondary_target = target * cfg.secondary_label_value\n        out_of_target_noise_intensity = cfg.smoothing_value / (len(LABELS) - 1)\n        out_of_target_noise_array = torch.ones(target.shape) * out_of_target_noise_intensity\n        secondary_target_with_noise = secondary_target + out_of_target_noise_array\n        secondary_target_with_noise = torch.clip(secondary_target_with_noise, min=0, max=cfg.secondary_label_value)\n\n        primary_target = np.isin(LABELS, self.df.loc[idx, \"primary_label\"]).astype(int)\n        primary_target = torch.tensor(primary_target, dtype=torch.float32)\n\n        primary_and_secondary_target_with_noise = primary_target + secondary_target_with_noise\n        new_target = torch.clip(primary_and_secondary_target_with_noise, min=0, max=1)\n        new_target = new_target - primary_target * cfg.smoothing_value\n        return new_target\n\n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            # Load and preprocess training data\n            pass\n        elif self.mode == 'valid':\n            # Load and preprocess validation data\n            pass\n        elif self.mode == 'test':\n            # Load and preprocess test data\n            pass\n        elif self.mode == 'clean':\n            # Load and preprocess clean data for visualization\n            pass\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Functionalities:**\n* **Normalization:** Adjusts spectrogram values to a standardized range.\n* **Wave Tiling and Cutoff:** Ensures all audio clips are of uniform length by trimming or tiling.\n* **Label Smoothing:** Applies smoothing to the target labels to handle class imbalance and improve generalization.\n* **Data Augmentation:** Integrates wave and spectrogram augmentations to enhance model robustness.","metadata":{}},{"cell_type":"markdown","source":"## Data Augmentation\nData augmentation techniques are employed to artificially expand the dataset, making the model more resilient to variations in the audio data.","metadata":{}},{"cell_type":"code","source":"if isTrain == True:\n    normal_augment = Compose([\n        OneOf([\n            Gain(min_gain_in_db=-15, max_gain_in_db=15, p=1.0),\n            GainTransition(min_gain_in_db=-24.0, max_gain_in_db=6.0, min_duration=0.2, max_duration=6.0, p=1.0)\n        ], p=cfg.aug_gain),\n\n        OneOf([\n            AddGaussianNoise(p=1),\n            AddColorNoise(p=1, min_snr_db=5, max_snr_db=20, min_f_decay=-3.01, max_f_decay=-3.01)\n        ], p=cfg.aug_noise),\n\n        PitchShift(min_semitones=-1, max_semitones=1, p=cfg.aug_wave_pitchshift),\n        Shift(p=cfg.aug_wave_shift)\n    ])\n    alb_transform = [\n        albumentations.XYMasking(num_masks_x=2, num_masks_y=1, \n                                 mask_x_length=cfg.size_x // 30, mask_y_length=cfg.n_mels // 30,\n                                 fill_value=0, mask_fill_value=0, p=cfg.aug_spec_xymasking),\n        albumentations.CoarseDropout(fill_value=0, min_holes=20, max_holes=50, p=cfg.aug_spec_coarsedrop),\n        albumentations.HorizontalFlip(p=cfg.aug_spec_hflip)    \n    ]\n    albumentations_augment = albumentations.Compose(alb_transform)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Mixup Techniques**\nMixup is a data augmentation technique that combines two samples to create a new sample, which can help in regularizing the model.","metadata":{}},{"cell_type":"code","source":"def mixup(data, targets, alpha, mode=\"same_wave\"):\n    if mode == \"same_wave\":\n        data = torch.tensor(data)\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        return new_data.numpy()\n    elif mode == \"other_wave\":\n        indices = torch.randperm(data.size(0))\n        shuffled_data = data[indices]\n        shuffled_targets = targets[indices]\n        lam = np.random.beta(alpha, alpha)\n        new_data = data * lam + shuffled_data * (1 - lam)\n        new_targets = targets * lam + shuffled_targets * (1 - lam)\n        return new_data, new_targets\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Spectrogram Transformation**\nTransforms raw audio waveforms into spectrograms, which are then used as input to the neural network.","metadata":{}},{"cell_type":"code","source":"spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels, f_min=cfg.fmin, f_max=cfg.fmax, mel_scale='slaney', center=True, pad_mode='reflect'\n).to(device)\n\nvalid_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels, f_min=cfg.fmin, f_max=cfg.fmax, mel_scale='slaney', center=True, pad_mode='reflect'\n).to(device)\n\ntest_spec_layer = torchaudio.transforms.MelSpectrogram(\n    sample_rate=cfg.sr, hop_length=cfg.test_hop_length, n_fft=cfg.n_fft,\n    n_mels=cfg.n_mels, f_min=cfg.fmin, f_max=cfg.fmax, mel_scale='slaney', center=True, pad_mode='reflect'\n).cpu()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"markdown","source":"### **BirdModel**\nA versatile neural network architecture built using the timm library, which supports various state-of-the-art models. The BirdModel class allows for different pooling strategies and includes a custom classification head.","metadata":{}},{"cell_type":"code","source":"class BirdModel(torch.nn.Module):\n    def __init__(self, model_name, pretrained, in_channels, num_classes, pool=\"default\"):\n        super().__init__()\n        self.pool = pool\n        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        \n        if pool == \"default\":\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3)\n        else:\n            self.backbone = timm.create_model(\n                model_name=model_name, pretrained=pretrained,\n                num_classes=0, in_chans=3, global_pool=\"\")\n        \n        in_features = self.backbone.num_features\n\n        self.max_pooling = torch.nn.Sequential(\n            torch.nn.AdaptiveMaxPool2d(1),\n            torch.nn.Flatten(start_dim=1, end_dim=-1)\n        )\n        self.avg_pooling = torch.nn.Sequential(\n            torch.nn.AdaptiveAvgPool2d(1),\n            torch.nn.Flatten(start_dim=1, end_dim=-1)\n        )\n        self.both_pooling_neck = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(2 * in_features),\n            torch.nn.Linear(in_features=2 * in_features, out_features=in_features)\n        )\n        \n        self.head = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(in_features),\n            torch.nn.Linear(in_features=in_features, out_features=256),\n            torch.nn.Hardswish(inplace=True),\n            torch.nn.Dropout(0.1),\n            torch.nn.Linear(in_features=256, out_features=len(LABELS))\n        )\n        \n        self.active = torch.nn.Sigmoid()\n    \n    def forward(self, x):\n        x = x.expand(-1, 3, -1, -1)\n        x = self.normalize(x)\n        x = self.backbone(x)\n\n        if self.pool == \"max\":\n            x = self.max_pooling(x)\n        elif self.pool == \"avg\":\n            x = self.avg_pooling(x)\n        elif self.pool == \"both\":\n            x_max = self.max_pooling(x)\n            x_avg = self.avg_pooling(x)\n            x = x_max + x_avg\n        \n        x = self.head(x)\n        return x\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Features:**\n1. **Backbone:** Utilizes models from the timm library, such as eca_nfnet_l0, convnext_small_fb_in22k_ft_in1k_384, and convnextv2_tiny_fcmae_ft_in22k_in1k_384.\n1. **Pooling Strategies:**\n1. * **Max Pooling:** Captures the most prominent features.\n1. * **Average Pooling:** Captures the average feature presence.\n1. * **Both:** Combines max and average pooling for richer feature representation.\n1. **Classification Head:** A sequence of batch normalization, linear layers, activation functions, and dropout for robust classification.\n1. **Activation Function:** Uses sigmoid activation for multi-label classification.","metadata":{}},{"cell_type":"markdown","source":"## Training Utilities","metadata":{}},{"cell_type":"markdown","source":"### **Setting Random Seeds**\nEnsures reproducibility by setting seeds for various random number generators.","metadata":{}},{"cell_type":"code","source":"def set_random_seed(seed: int = 42, deterministic: bool = False):\n    \"\"\"Set seeds for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loss Function: BCEFocalLoss**\nImplements the Binary Cross Entropy Focal Loss to handle class imbalance by focusing more on hard-to-classify examples.","metadata":{}},{"cell_type":"code","source":"class BCEFocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, preds, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n        probas = torch.sigmoid(preds)\n        \n        tmp = targets * self.alpha * (1. - probas) ** self.gamma * bce_loss\n        smp = (1. - targets) * probas ** self.gamma * bce_loss\n        \n        loss = tmp + smp\n        loss = loss.mean()\n        return loss\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Metrics**\nUtilizes various metrics to evaluate model performance, including AUC, F1 Score, Precision, and Recall.","metadata":{}},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"markdown","source":"### **Initialization**\nSets up the model, optimizer, scheduler, scaler, and loss function based on the configuration.","metadata":{}},{"cell_type":"code","source":"def initialization():\n    model = BirdModel(model_name=cfg.model_name, pretrained=True, in_channels=3, num_classes=len(LABELS), pool=cfg.pool_type)\n    \n    if cfg.optimizer == 'adan':\n        optimizer = Adan(model.parameters(), lr=cfg.lr, betas=(0.02, 0.08, 0.01), weight_decay=cfg.weight_decay)\n    else:\n        optimizer = torch.optim.AdamW(params=model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer, epochs=cfg.max_epoch,\n        pct_start=0.0, steps_per_epoch=len(train_dataloader),\n        max_lr=cfg.lr, div_factor=25, final_div_factor=4.0e-01\n    )\n    \n    scaler = amp.GradScaler(enabled=cfg.enable_amp)\n    if cfg.loss_type == \"BCEFocalLoss\":\n        loss_func = BCEFocalLoss(alpha=1)\n    elif cfg.loss_type == \"BCEWithLogitsLoss\":\n        loss_func = torch.nn.BCEWithLogitsLoss()\n    \n    return model.to(device), optimizer, scheduler, scaler, loss_func.to(device)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Training Functions**\ntrain_one_loop\nHandles a single epoch of training without mixup augmentation.\n\n","metadata":{}},{"cell_type":"code","source":"def train_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0\n    model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader, leave=False, desc=\"[train]\")):\n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        del data, label, loss\n        count += 1\n\n    trainloss /= len(dataloader)\n    if cfg.wandb:\n        wandb.log({\"train_loss\": trainloss, \"lr\": scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mixup_one_loop\nHandles a single epoch of training with mixup augmentation.","metadata":{}},{"cell_type":"code","source":"def mixup_one_loop(model, optimizer, scaler, scheduler, dataloader, loss_fn):\n    trainloss = 0\n    model.train()\n\n    count = 0\n    for idx, (data, label) in enumerate(tqdm(dataloader, leave=False, desc=\"[train]\")):\n        if np.random.random() > cfg.aug_spec_mixup_prob:\n            data, label = mixup(data=data, targets=label, alpha=cfg.alpha, mode=\"other_wave\")\n        else:\n            data, label = spec_mixup(data=data, targets=label)\n        data, label = data.to(device), label.to(device)\n        \n        optimizer.zero_grad()\n        with amp.autocast(cfg.enable_amp, dtype=torch.bfloat16):\n            pred = model.forward(data)\n            loss = loss_fn(pred, label)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n        \n        trainloss += loss.item()\n        del data, label, loss\n        count += 1\n\n    trainloss /= len(dataloader)\n    if cfg.wandb:\n        wandb.log({\"train_loss\": trainloss, \"lr\": scheduler.get_lr()[0]})\n    return model, optimizer, scaler, scheduler, trainloss\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Evaluation Function**\nEvaluates the model on the validation set, computing various metrics.","metadata":{}},{"cell_type":"code","source":"def evaluate_validation(model, dataloader, loss_fn):\n    validloss = 0\n    model.eval()\n\n    preds, trues, targets = [], [], []\n    \n    for idx, (data, label) in enumerate(tqdm(dataloader, leave=False, desc=\"[valid]\")):\n        d = data[0].unsqueeze(1)\n        label = label[0]\n        \n        d = d.to(device)\n        pred = model.forward(d)\n\n        preds.extend(pred.detach().cpu())\n        trues.extend(label)\n        targets.extend(label.argmax(axis=1))\n        \n    t = torch.stack(preds)\n    t = torch.sigmoid(t)\n    targets = torch.tensor(targets)\n    y_trues = torch.stack(trues)\n\n    validloss = loss_fn(torch.stack(preds), torch.stack(trues))\n    \n    sk_f1_30 = metrics.f1_score(np.array(y_trues), np.array(t) > 0.30, average=\"micro\")\n    sk_f1_50 = metrics.f1_score(np.array(y_trues), np.array(t) > 0.50, average=\"micro\")\n    \n    auc = multiclass_auroc(input=t, target=targets, num_classes=len(LABELS), average=\"macro\").item()\n\n    prec = multiclass_precision(input=t, target=targets, num_classes=len(LABELS), average=\"macro\").item()\n    \n    f1 = multiclass_f1_score(input=t, target=torch.tensor(targets), num_classes=len(LABELS), average=\"micro\").item()\n    f1_macro = multiclass_f1_score(input=t, target=torch.tensor(targets), num_classes=len(LABELS), average=\"macro\").item()\n\n    t_03 = (t > 0.3).int()\n    t_03 = torch.tensor(t_03, dtype=torch.int64)\n    f1_03 = multiclass_f1_score(input=t_03, target=torch.tensor(targets), num_classes=len(LABELS), average=\"micro\").item()\n\n    t_05 = (t > 0.5).int()\n    t_05 = torch.tensor(t_05, dtype=torch.int64)\n    f1_05 = multiclass_f1_score(input=t_05, target=torch.tensor(targets), num_classes=len(LABELS), average=\"micro\").item()\n\n    if cfg.wandb:\n        wandb.log({\n            \"valid_loss\": validloss,\n            \"AUC\": auc,\n            \"precision\": prec, \n            \"F1\": f1,\n            \"F1_macro\": f1_macro,\n            \"F1 30%\": f1_03,\n            \"F1 50%\": f1_05\n        })\n    return validloss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Process\n","metadata":{}},{"cell_type":"markdown","source":"### **Experiment Naming and Setup**\nThe experiment names are managed based on whether the environment is Kaggle or local, and whether the task is training or inference.\n\n","metadata":{}},{"cell_type":"code","source":"if isTrain == False and isInference == True:\n    newDir = False\nelse:\n    newDir = True\nprint(newDir)\nFalse\n\nif KAGGLE == False:\n    if isTrain == True:\n        name = sorted(glob.glob(\"exp1*.ipynb\"))[-1][:-6]\n        print(f\"filename is {name}\")\n    else:\n        name = \"exp1057\"\n        print(f\"filename is {name}\")\nelse:\n    name = \"exp1057\"\n    name = f'bird2024{name}'\n    print(f\"filename is {name}\")\ntrial = \"trial1\"\np_name = f\"BirdCLEF_cv_ver2\"\nfilename is bird2024exp1057\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Directory and Logging Setup**\nCreates necessary directories for checkpoints and initializes Weights & Biases (WandB) for experiment tracking.","metadata":{}},{"cell_type":"code","source":"if KAGGLE == False:\n    if cfg.wandb == True:\n        wandb.login(key=\"your_wandb_api_key\")\n    \n    if newDir == True:\n        new_dir_path_recursive = f\"{name}/checkpoint\"\n        os.makedirs(new_dir_path_recursive, exist_ok=True)\n        shutil.rmtree(new_dir_path_recursive)\n        os.makedirs(new_dir_path_recursive, exist_ok=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Cross-Validation Setup**\nImplements Stratified K-Fold cross-validation to ensure each fold has a representative distribution of classes.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nskf = StratifiedKFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train_csv, train_csv['primary_label'])):\n    train_csv.loc[valid_index, 'fold'] = int(fold)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training Loop Execution**\nThe training process iterates over each fold, training the model and evaluating its performance on the validation set.","metadata":{}},{"cell_type":"code","source":"if isTrain == True:\n    set_random_seed(seed=42)\n    \n    if cfg.wandb == True:\n        wandb.init(project=p_name, name=f\"{name}\", config=tmp_params)\n        \n    for fold in cfg.inference_folds:\n        train_ = train_csv.loc[train_csv[\"fold\"] != fold]\n\n        if cfg.oversample == True:\n            train = get_oversampled_df(df=train_)\n        else:\n            train = train_\n        \n        augme_dataset = BirdCLEF_Dataset(df=train, augmentation=True, mode='train')\n        augme_dataloader = torch.utils.data.DataLoader(dataset=augme_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n\n        train_dataset = BirdCLEF_Dataset(df=train, augmentation=False, mode='train')\n        train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=cfg.train_batchsize, shuffle=True)\n        \n        valid = train_csv.loc[train_csv[\"fold\"] == fold]\n        valid_dataset = BirdCLEF_Dataset(df=valid, augmentation=False, mode='valid')\n        valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=cfg.valid_batchsize, shuffle=False)\n    \n        model, optimizer, scheduler, scaler, loss_func = initialization()\n    \n        best_f1 = 0\n        best_auc = 0\n        best_loss = 1.00000\n        for e in range(cfg.max_epoch):\n            start_time = time.time()\n            if e < cfg.aug_epoch:\n                if cfg.aug_spec_mixup > np.random.random():\n                    model, optimizer, scaler, scheduler, train_loss = mixup_one_loop(\n                        model=model, optimizer=optimizer, scaler=scaler, \n                        scheduler=scheduler, dataloader=augme_dataloader, loss_fn=loss_func\n                    )\n                else:\n                    model, optimizer, scaler, scheduler, train_loss = train_one_loop(\n                        model=model, optimizer=optimizer, scaler=scaler, \n                        scheduler=scheduler, dataloader=augme_dataloader, loss_fn=loss_func\n                    )\n            else:\n                model, optimizer, scaler, scheduler, train_loss = train_one_loop(\n                    model=model, optimizer=optimizer, scaler=scaler, \n                    scheduler=scheduler, dataloader=train_dataloader, loss_fn=loss_func\n                )\n            \n            valid_loss, auc, f1, f1_03, f1_05, sk_f1_30, sk_f1_50 = evaluate_validation(\n                model=model, dataloader=valid_dataloader, loss_fn=loss_func\n            )\n            \n            if best_loss > valid_loss:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] AUC{auc: .4f}, F1{f1: .4f}, F1_03{f1_03: .4f}, F1_05{f1_05: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] SKF1_03{sk_f1_30: .4f}, SKF1_05{sk_f1_50: .4f}\")\n                print(f\"[epoch {str(e).zfill(2)}] valid_loss {valid_loss: .6f}\")\n                print(f\"[epoch {str(e).zfill(2)}] update loss {best_loss: .6f} --> {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] update auc score {best_auc: .6f} --> {auc: .6f} {(end_time - start_time): .1f}[s]\")\n                model_name = f'{name}/checkpoint/fold_{fold}_snapshot_epoch_{str(e).zfill(2)}.pth'\n                best_model = model\n                best_loss = valid_loss\n                best_auc = auc\n                best_f1 = f1\n            else:\n                end_time = time.time()\n                print(f\"[epoch {str(e).zfill(2)}] NOT update loss {best_loss: .6f} <-- {valid_loss: .6f} {(end_time - start_time): .1f}[s]\")\n                print(f\"[epoch {str(e).zfill(2)}] NOT update score {best_auc: .6f} <-- {auc: .6f} {(end_time - start_time): .1f}[s]\")\n\n        if cfg.wandb:\n            wandb.log({\"best_loss\": best_loss, \"best_f1\": best_f1, \"best_auc\": best_auc})\n\n        torch.save(best_model.state_dict(), model_name)\n        \n        del model, best_model\n        gc.collect()\n        torch.cuda.empty_cache()\n        print(\"--\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Process Breakdown:**\n1. **Seed Initialization:** Ensures reproducible results.\n1. **WandB Initialization:** Logs experiment details for monitoring.\n1. **Cross-Validation Loop:** Iterates over each specified fold.\n1. * **Data Splitting:** Separates training and validation data based on the current fold.\n1. * **Oversampling:** Applies oversampling to handle class imbalance if enabled.\n1. * **Dataset and Dataloader Creation:** Prepares data loaders for training and validation.\n1. **Model Initialization:** Sets up the model, optimizer, scheduler, scaler, and loss function.\n1. **Epoch Loop:** Trains the model over multiple epochs.\n1. 1. **Augmentation Phase:** Applies mixup augmentation during initial epochs.\n1. 1. **Training Phase:** Conducts forward and backward passes, updates weights.\n1. 1. **Validation Phase:** Evaluates model performance on the validation set.\n1. 1. **Checkpointing:** Saves the model checkpoint if validation loss improves.\n1. **Cleanup:** Frees up memory by deleting models and clearing caches.","metadata":{}},{"cell_type":"markdown","source":"## **Inference**\nAfter training, the model is used to make predictions on test data. The trained models are converted to the ONNX format for optimized inference.","metadata":{}},{"cell_type":"markdown","source":"### **Loading Models**\nLoads the best model checkpoints and prepares them for inference.","metadata":{}},{"cell_type":"code","source":"models = dict()\nmodels_names = dict()\n\nfor fold in cfg.inference_folds:\n    if KAGGLE == True:\n        bestmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.pth\"))[-1]\n    else:\n        bestmodel_path = sorted(glob.glob(f\"{name}/checkpoint/fold_{fold}*.pth\"))[-1]\n    print(bestmodel_path)\n    model = BirdModel(model_name=cfg.model_name, pretrained=False, in_channels=1, num_classes=len(LABELS))\n    model.load_state_dict(torch.load(bestmodel_path, map_location=torch.device('cpu')))\n    model = model.eval()\n    models[fold] = model\n\n    models_names[fold] = bestmodel_path.split(\".\")[0] + \".onnx\"\n    print(models_names[fold])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Preparing Test Data**\nSets up the test dataset and dataloader based on the environment.","metadata":{}},{"cell_type":"code","source":"if KAGGLE == True:\n    test_audio_dir = f\"{cfg.dir}test_soundscapes/\"\n    file_list = glob.glob(test_audio_dir + \"*.ogg\")\n    file_list = sorted(file_list)\nelse:\n    test_audio_dir = f\"{cfg.dir}unlabeled_soundscapes/\"\n    file_list = glob.glob(test_audio_dir + \"*.ogg\")\n    file_list = sorted(file_list)[:3]\ntest_dataset = BirdCLEF_Dataset(df=file_list, mode=\"test\")\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Exporting Models to ONNX**\nConverts the trained PyTorch models to the ONNX format for efficient inference.","metadata":{}},{"cell_type":"code","source":"input_tensor = torch.randn((48, 1, cfg.n_mels, cfg.size_x + 1))  # input shape\noutput_names = ['output']\ninput_names = [\"x\"]\n\nif KAGGLE == False:\n    for fold in cfg.inference_folds:\n        torch.onnx.export(\n            model=models[fold].eval(),\n            args=(input_tensor),\n            input_names=input_names,\n            output_names=output_names,\n            f=models_names[fold]\n        )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loading ONNX Models**\nLoads the ONNX models using onnxruntime for inference.","metadata":{}},{"cell_type":"code","source":"onnx_sessions = dict()\n\nfor fold in cfg.inference_folds:\n    if KAGGLE == True:\n        onnxmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n    else:\n        onnxmodel_path = sorted(glob.glob(f\"{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n    print(onnxmodel_path)\n    models_names[fold] = onnxmodel_path\n\n    onnx_model = onnx.load(models_names[fold])\n    onnx_model_graph = onnx_model.graph\n    onnx_session = ort.InferenceSession(onnx_model.SerializeToString())\n\n    onnx_sessions[fold] = onnx_session\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Making Predictions**\nPerforms inference on the test dataset and aggregates predictions from all folds.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\npredictions = []\nfor data in tqdm(test_dataloader):\n    preds = []\n    for fold in cfg.inference_folds:\n        session = onnx_sessions[fold]\n        pred = session.run(output_names, {input_names[0]: data[0].numpy()})[0]\n        pred = torch.sigmoid(torch.tensor(pred))\n        preds.append(pred)\n    preds_per_batch = torch.stack(preds, axis=0).mean(axis=0)\n    predictions.extend(preds_per_batch)\n\nif len(predictions) > 0:\n    predictions = torch.stack(predictions)\nelse:\n    predictions = predictions\nend_time = time.time()\nuse_time = end_time - start_time\nprint(f\"{cfg.inference_folds}fold +     3ogg is {round(use_time,1)}[s]\")\nprint(f\"{cfg.inference_folds}fold + 1,100ogg is {round(1100*use_time/3,1)}[s], {round(1100*use_time/3/60,1)}[m]\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualization**\nProvides visual insights into model predictions and performance metrics.","metadata":{}},{"cell_type":"markdown","source":"### **Example Predictions**\nDisplays spectrograms of training and validation data to visualize how the model interprets different bird sounds.","metadata":{}},{"cell_type":"code","source":"if isTrain:\n    print(\"train data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True, mode=\"train\")\n    data, target = dataset[270]\n    fig, ax = plt.subplots(figsize=(6,4))\n    plt.imshow(data[0], cmap=\"jet\", origin=\"lower\")\n    plt.show()\n    \n    print(\"validation data\")\n    dataset = BirdCLEF_Dataset(df=train_csv, augmentation=True, mode=\"valid\")\n    data, target = dataset[270]\n    fig, axes = plt.subplots(figsize=(12,8), nrows=len(data), tight_layout=True)\n    for idx, ax in enumerate(axes.ravel()):\n        ax.imshow(data[idx], cmap=\"jet\", origin=\"lower\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Evaluation Metrics Visualization**\nPlots distribution of labels and corresponding AUC scores.","metadata":{}},{"cell_type":"code","source":"if KAGGLE == False:\n    train_csv.groupby(\"fold\", as_index=False)[\"primary_label\"].value_counts()\n\n# Additional plots for label distribution and model performance\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Prediction Visualization**\nVisualizes model predictions against true labels for specific data points.\n\n","metadata":{}},{"cell_type":"code","source":"if KAGGLE == False:\n    def predict_and_visualize(data_index):\n        use_fold = 4\n        c_dataset, df = get_fold_data(fold=use_fold)\n        model = models[use_fold].to(device)\n        \n        prediction = model.forward(c_dataset[data_index][0].to(device)).cpu().detach()\n        prediction = torch.sigmoid(prediction)\n        \n        df_index = df.index[data_index]\n        true_labels = df.loc[df_index, \"new_target\"].split()\n        true_guide_pos = [LABELS.index(l) + 0.5 for l in true_labels]\n    \n        fig, ax = plt.subplots(figsize=(24, 1.5))\n        sns.heatmap(prediction, cmap=\"jet\", vmin=0, vmax=1)\n        ax.set_xticks(np.arange(0, 182))\n        ax.set_xticklabels(LABELS, fontsize=8)\n        \n        ax.set_yticks(np.arange(0, prediction.shape[0]))\n        ax.set_yticklabels(np.arange(1, 1 + prediction.shape[0]) * 5)\n        \n        for pos in true_guide_pos:\n            ax.axvline(x=pos, color=\"red\", ls=\"--\", lw=0.9)\n        \n        plt.xticks(ticks=np.arange(0, 182), labels=LABELS, color='black')\n        plt.title(c_dataset[data_index][1])\n        plt.show()\n    \n        return prediction\n\n    # Example visualizations\n    N = len(train_csv.loc[train_csv[\"fold\"] == fold]) // 30\n    print(N)\n    \n    predict_and_visualize(data_index=0)\n    predict_and_visualize(data_index=1)\n    predict_and_visualize(data_index=2)\n    predict_and_visualize(data_index=3)\n    predict_and_visualize(data_index=4)\n    \n    for i in range(N):\n        try:\n            predict_and_visualize(data_index=i * 30)\n        except:\n            pass\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **ONNX Export**\nConverts trained PyTorch models into the ONNX format, facilitating optimized and platform-independent deployment.","metadata":{}},{"cell_type":"markdown","source":"### **Setting ONNX Configuration**\nDefines input and output parameters for the ONNX export process.","metadata":{}},{"cell_type":"code","source":"input_tensor = torch.randn((48, 1, cfg.n_mels, cfg.size_x + 1))  # Input shape\noutput_names = ['output']\ninput_names = [\"x\"]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Exporting Models**\nExports each trained model to the ONNX format.","metadata":{}},{"cell_type":"code","source":"if KAGGLE == False:\n    for fold in cfg.inference_folds:\n        torch.onnx.export(\n            model=models[fold].eval(),\n            args=(input_tensor),\n            input_names=input_names,\n            output_names=output_names,\n            f=models_names[fold]\n        )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Verifying ONNX Models**\nLoads and verifies the exported ONNX models to ensure correctness.","metadata":{}},{"cell_type":"code","source":"import onnx\nimport onnxruntime as ort\n\nfor fold in cfg.inference_folds:\n    if KAGGLE == True:\n        onnxmodel_path = sorted(glob.glob(f\"/kaggle/input/{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n    else:\n        onnxmodel_path = sorted(glob.glob(f\"{name}/checkpoint/fold_{fold}*.onnx\"))[-1]\n    print(onnxmodel_path)\n    models_names[fold] = onnxmodel_path\n\n    onnx_model = onnx.load(models_names[fold])\n    onnx_model_graph = onnx_model.graph\n    onnx_session = ort.InferenceSession(onnx_model.SerializeToString())\n\n    onnx_sessions[fold] = onnx_session\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Performing Inference with ONNX Models**\nUses onnxruntime to perform fast inference on test data.","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\npredictions = []\nfor data in tqdm(test_dataloader):\n    preds = []\n    for fold in cfg.inference_folds:\n        session = onnx_sessions[fold]\n        pred = session.run(output_names, {input_names[0]: data[0].numpy()})[0]\n        pred = torch.sigmoid(torch.tensor(pred))\n        preds.append(pred)\n    preds_per_batch = torch.stack(preds, axis=0).mean(axis=0)\n    predictions.extend(preds_per_batch)\n\nif len(predictions) > 0:\n    predictions = torch.stack(predictions)\nelse:\n    predictions = predictions\nend_time = time.time()\nuse_time = end_time - start_time\nprint(f\"{cfg.inference_folds}fold +     3ogg is {round(use_time,1)}[s]\")\nprint(f\"{cfg.inference_folds}fold + 1,100ogg is {round(1100*use_time/3,1)}[s], {round(1100*use_time/3/60,1)}[m]\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Generating Submission File**\nCreates a submission CSV file based on the model predictions.","metadata":{}},{"cell_type":"code","source":"bird_cols = sample_submission.columns[1:]\ndf = pd.DataFrame(columns=['row_id'] + list(bird_cols))\n\nrow_list = []\nfor file in file_list:\n    dataname = file.split(\"/\")[-1][:-4]\n    for i in range(int(4 * 60 / 5)):\n        row = f\"{dataname}_{(i + 1) * 5}\"\n        row_list.append(row)\ndf['row_id'] = row_list\n\nif len(predictions) < 1:\n    pass\nelse:\n    df[bird_cols] = predictions\ndf.to_csv(\"submission.csv\", index=False)\ndf[:48].set_index(\"row_id\").max().T.plot(kind=\"bar\", figsize=(24, 4))\n","metadata":{},"execution_count":null,"outputs":[]}]}